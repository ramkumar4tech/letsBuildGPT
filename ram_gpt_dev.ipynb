{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramkumar4tech/letsBuildGPT/blob/main/ram_gpt_dev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b0c71b22-2576-49ff-9565-88c1227ead08",
      "metadata": {
        "id": "b0c71b22-2576-49ff-9565-88c1227ead08",
        "outputId": "2ec5a40d-b342-4a84-ea30-f4f0621870b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-07 07:00:16--  https://raw.githubusercontent.com/ramkumar4tech/letsBuildGPT/main/mmm_blog.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5703 (5.6K) [text/plain]\n",
            "Saving to: ‘mmm_blog.txt’\n",
            "\n",
            "\rmmm_blog.txt          0%[                    ]       0  --.-KB/s               \rmmm_blog.txt        100%[===================>]   5.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-09-07 07:00:16 (55.7 MB/s) - ‘mmm_blog.txt’ saved [5703/5703]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/ramkumar4tech/letsBuildGPT/main/mmm_blog.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "65899bf8-03f4-43b5-b32c-aa5cbe0b2948",
      "metadata": {
        "id": "65899bf8-03f4-43b5-b32c-aa5cbe0b2948",
        "outputId": "0052c075-a5d8-430b-d321-61317058dead",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi there. If we haven’t met, my name is Mr. Money Mustache. I’m the freaky financial magician who retired along with a lovely wife at age 30 in order to start a family, as well as start living a great life. We did this on two normal salaries with no lottery winnings or Silicon Valley buyout windfalls, by living what we thought was a wonderful and fulfilling existence. It was only after quitting the rat race that we looked around and realized why we had become financially independent while most people, even with higher incomes, end up stuck needing to work until age 65 or later.\n",
            "\n",
            "I’m writing this post to use as kind of a permanent “Hello!”, since at any given moment in time, about half of the readers of this blog are pretty new, and casting around wondering where to start on a giant site like this with over 500 published articles. Most people arrive with the same question:\n",
            "\n",
            "“I hear Mr. Money Mustache writes some useful stuff and many people are building happy, wealthy lives for themselv\n"
          ]
        }
      ],
      "source": [
        "# Load the file\n",
        "with open('mmm_blog.txt','r') as file:\n",
        "  text = file.read()\n",
        "\n",
        "print(text[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find unique tokens and encode/decode the text content\n",
        "tokens = sorted(list(set(text)))\n",
        "print(''.join(tokens))\n",
        "print(len(tokens))\n",
        "\n",
        "stoi = {ch:i for i,ch in enumerate(tokens)}\n",
        "itos = {i:ch for i,ch in enumerate(tokens)}\n",
        "encode = lambda s : [stoi[c] for c in s]\n",
        "decode = lambda l : ''.join([itos[i] for i in l])\n",
        "\n",
        "print(encode('TestingParam'))\n",
        "print(decode(encode('TestingParam')))"
      ],
      "metadata": {
        "id": "cqIGcmOzSM4_",
        "outputId": "a42d72cd-4d8d-4750-f7ea-64569b344c09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "cqIGcmOzSM4_",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !%(),-.01234567:?ABCDEFGHIKLMNOPRSTUVWYabcdefghijklmnopqrstuvwxyz–’“”\n",
            "71\n",
            "[36, 45, 59, 60, 49, 54, 47, 33, 41, 58, 41, 53]\n",
            "TestingParam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare batch data for processing\n",
        "batch_size = 4\n",
        "block_size = 8\n",
        "\n",
        "import torch\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:100])\n",
        "\n",
        "# Splitting training and validation test data\n",
        "n = int(0.9*len(text))\n",
        "print(n)\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "import torch\n",
        "torch.manual_seed(1330)\n",
        "batch_size = 4\n",
        "block_size = 8\n",
        "print(torch.randint(len(data)-block_size,(batch_size,)))\n",
        "\n",
        "def get_batch(dataName):\n",
        "  data = train_data if dataName=='train' else val_data\n",
        "\n"
      ],
      "metadata": {
        "id": "m8Fu-UFrU7pI",
        "outputId": "93ca8c1c-fc80-43fa-836b-4e4dd65e70a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "m8Fu-UFrU7pI",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5629]) torch.int64\n",
            "tensor([26, 49,  1, 60, 48, 45, 58, 45,  8,  1, 27, 46,  1, 63, 45,  1, 48, 41,\n",
            "        62, 45, 54, 68, 60,  1, 53, 45, 60,  6,  1, 53, 65,  1, 54, 41, 53, 45,\n",
            "         1, 49, 59,  1, 30, 58,  8,  1, 30, 55, 54, 45, 65,  1, 30, 61, 59, 60,\n",
            "        41, 43, 48, 45,  8,  1, 27, 68, 53,  1, 60, 48, 45,  1, 46, 58, 45, 41,\n",
            "        51, 65,  1, 46, 49, 54, 41, 54, 43, 49, 41, 52,  1, 53, 41, 47, 49, 43,\n",
            "        49, 41, 54,  1, 63, 48, 55,  1, 58, 45])\n",
            "5066\n",
            "tensor([1999,  405,  730, 5068])\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}